{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Results Analysis\n",
        "\n",
        "This notebook creates the final deliverable visualizations:\n",
        "- Accuracy vs dataset size Pareto curve\n",
        "- Accuracy comparison (GA vs random baselines)\n",
        "- Training efficiency plots (accuracy per sample)\n",
        "- Summary tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.insert(0, str(Path().absolute().parent))\n",
        "import config\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load evaluation results\n",
        "eval_path = config.RESULTS_DIR / \"evaluation.json\"\n",
        "if eval_path.exists():\n",
        "    with open(eval_path, 'r') as f:\n",
        "        eval_results = json.load(f)\n",
        "    print(f\"Loaded evaluation results from {eval_path}\")\n",
        "else:\n",
        "    print(f\"Evaluation results not found at {eval_path}\")\n",
        "    print(\"Run 'python training/evaluate_models.py' first.\")\n",
        "    eval_results = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accuracy vs Dataset Size Pareto Curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if eval_results:\n",
        "    # Extract data\n",
        "    k_values = []\n",
        "    ga_accs = []\n",
        "    random_mean_accs = []\n",
        "    random_std_accs = []\n",
        "    \n",
        "    for k in config.K_VALUES:\n",
        "        ga_key = f'ga_k{k}'\n",
        "        random_key = f'random_k{k}'\n",
        "        \n",
        "        if ga_key in eval_results['results']:\n",
        "            k_values.append(k)\n",
        "            ga_accs.append(eval_results['results'][ga_key]['test_accuracy'])\n",
        "            \n",
        "            if random_key in eval_results['results']:\n",
        "                random_mean_accs.append(eval_results['results'][random_key]['mean_accuracy'])\n",
        "                random_std_accs.append(eval_results['results'][random_key]['std_accuracy'])\n",
        "            else:\n",
        "                random_mean_accs.append(None)\n",
        "                random_std_accs.append(None)\n",
        "    \n",
        "    # Full dataset accuracy\n",
        "    full_acc = None\n",
        "    if 'full_dataset' in eval_results['results']:\n",
        "        full_acc = eval_results['results']['full_dataset']['test_accuracy']\n",
        "    \n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    \n",
        "    # GA-selected\n",
        "    ax.plot(k_values, ga_accs, 'o-', linewidth=3, markersize=10, \n",
        "            label='GA-Selected', color='steelblue', zorder=3)\n",
        "    \n",
        "    # Random baseline\n",
        "    valid_k = [k for k, acc in zip(k_values, random_mean_accs) if acc is not None]\n",
        "    valid_mean = [acc for acc in random_mean_accs if acc is not None]\n",
        "    valid_std = [std for std, acc in zip(random_std_accs, random_mean_accs) if acc is not None]\n",
        "    \n",
        "    if valid_k:\n",
        "        ax.errorbar(valid_k, valid_mean, yerr=valid_std, fmt='s-', \n",
        "                   linewidth=2, markersize=8, capsize=5, capthick=2,\n",
        "                   label='Random Baseline (mean ± std)', color='orange', zorder=2)\n",
        "    \n",
        "    # Full dataset (horizontal line)\n",
        "    if full_acc is not None:\n",
        "        ax.axhline(y=full_acc, color='red', linestyle='--', linewidth=2, \n",
        "                  label=f'Full Dataset ({full_acc:.2f}%)', zorder=1)\n",
        "    \n",
        "    ax.set_xlabel('Subset Size (k)', fontsize=13, fontweight='bold')\n",
        "    ax.set_ylabel('Test Accuracy (%)', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Accuracy vs Dataset Size', fontsize=16, fontweight='bold')\n",
        "    ax.legend(fontsize=11, loc='best')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/accuracy_vs_size.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Efficiency (Accuracy per Sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if eval_results:\n",
        "    # Extract efficiency data\n",
        "    k_values = []\n",
        "    ga_efficiencies = []\n",
        "    random_mean_efficiencies = []\n",
        "    \n",
        "    for k in config.K_VALUES:\n",
        "        ga_key = f'ga_k{k}'\n",
        "        random_key = f'random_k{k}'\n",
        "        \n",
        "        if ga_key in eval_results['results']:\n",
        "            k_values.append(k)\n",
        "            ga_eff = eval_results['results'][ga_key].get('training_efficiency')\n",
        "            ga_efficiencies.append(ga_eff if ga_eff is not None else 0)\n",
        "            \n",
        "            if random_key in eval_results['results']:\n",
        "                random_eff = eval_results['results'][random_key].get('mean_efficiency')\n",
        "                random_mean_efficiencies.append(random_eff if random_eff is not None else 0)\n",
        "            else:\n",
        "                random_mean_efficiencies.append(0)\n",
        "    \n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    \n",
        "    ax.plot(k_values, ga_efficiencies, 'o-', linewidth=3, markersize=10, \n",
        "            label='GA-Selected', color='steelblue', zorder=3)\n",
        "    \n",
        "    valid_k = [k for k, eff in zip(k_values, random_mean_efficiencies) if eff > 0]\n",
        "    valid_eff = [eff for eff in random_mean_efficiencies if eff > 0]\n",
        "    \n",
        "    if valid_k:\n",
        "        ax.plot(valid_k, valid_eff, 's-', linewidth=2, markersize=8,\n",
        "               label='Random Baseline (mean)', color='orange', zorder=2)\n",
        "    \n",
        "    ax.set_xlabel('Subset Size (k)', fontsize=13, fontweight='bold')\n",
        "    ax.set_ylabel('Training Efficiency (Accuracy / k)', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Training Efficiency vs Dataset Size', fontsize=16, fontweight='bold')\n",
        "    ax.legend(fontsize=11, loc='best')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/training_efficiency.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if eval_results:\n",
        "    # Create summary table\n",
        "    rows = []\n",
        "    \n",
        "    for k in config.K_VALUES:\n",
        "        ga_key = f'ga_k{k}'\n",
        "        random_key = f'random_k{k}'\n",
        "        \n",
        "        row = {'k': k}\n",
        "        \n",
        "        if ga_key in eval_results['results']:\n",
        "            ga_result = eval_results['results'][ga_key]\n",
        "            row['GA Accuracy'] = f\"{ga_result['test_accuracy']:.2f}%\"\n",
        "            row['GA Efficiency'] = f\"{ga_result.get('training_efficiency', 0):.4f}\"\n",
        "            row['GA Macro F1'] = f\"{ga_result['f1_scores']['macro']:.4f}\"\n",
        "        else:\n",
        "            row['GA Accuracy'] = 'N/A'\n",
        "            row['GA Efficiency'] = 'N/A'\n",
        "            row['GA Macro F1'] = 'N/A'\n",
        "        \n",
        "        if random_key in eval_results['results']:\n",
        "            random_result = eval_results['results'][random_key]\n",
        "            row['Random Accuracy'] = f\"{random_result['mean_accuracy']:.2f}% ± {random_result['std_accuracy']:.2f}%\"\n",
        "            row['Random Efficiency'] = f\"{random_result.get('mean_efficiency', 0):.4f}\"\n",
        "        else:\n",
        "            row['Random Accuracy'] = 'N/A'\n",
        "            row['Random Efficiency'] = 'N/A'\n",
        "        \n",
        "        rows.append(row)\n",
        "    \n",
        "    # Full dataset row\n",
        "    if 'full_dataset' in eval_results['results']:\n",
        "        full_result = eval_results['results']['full_dataset']\n",
        "        rows.append({\n",
        "            'k': 'Full',\n",
        "            'GA Accuracy': 'N/A',\n",
        "            'GA Efficiency': 'N/A',\n",
        "            'GA Macro F1': 'N/A',\n",
        "            'Random Accuracy': 'N/A',\n",
        "            'Random Efficiency': 'N/A',\n",
        "            'Full Accuracy': f\"{full_result['test_accuracy']:.2f}%\",\n",
        "            'Full Macro F1': f\"{full_result['f1_scores']['macro']:.4f}\"\n",
        "        })\n",
        "    \n",
        "    # Create DataFrame and display\n",
        "    df = pd.DataFrame(rows)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SUMMARY TABLE\")\n",
        "    print(\"=\"*80)\n",
        "    print(df.to_string(index=False))\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Save to CSV\n",
        "    df.to_csv('results/summary_table.csv', index=False)\n",
        "    print(\"\\nSaved summary table to results/summary_table.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
